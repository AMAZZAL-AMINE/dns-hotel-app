"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.fixS3Url = exports.uploadWithPresignedPostWithRetryAsync = exports.uploadFileAtPathToS3Async = void 0;
const tslib_1 = require("tslib");
const assert_1 = tslib_1.__importDefault(require("assert"));
const form_data_1 = tslib_1.__importDefault(require("form-data"));
const fs_extra_1 = tslib_1.__importDefault(require("fs-extra"));
const nullthrows_1 = tslib_1.__importDefault(require("nullthrows"));
const promise_retry_1 = tslib_1.__importDefault(require("promise-retry"));
const url_1 = require("url");
const fetch_1 = tslib_1.__importDefault(require("./fetch"));
const UploadSessionMutation_1 = require("./graphql/mutations/UploadSessionMutation");
async function uploadFileAtPathToS3Async(type, path, handleProgressEvent) {
    const presignedPost = await UploadSessionMutation_1.UploadSessionMutation.createUploadSessionAsync(type);
    (0, assert_1.default)(presignedPost.fields.key, 'key is not specified in in presigned post');
    const response = await uploadWithPresignedPostWithProgressAsync(path, presignedPost, handleProgressEvent);
    const location = (0, nullthrows_1.default)(response.headers.get('location'), `location does not exist in response headers (make sure you're uploading to AWS S3)`);
    const url = fixS3Url(location);
    return { url, bucketKey: presignedPost.fields.key };
}
exports.uploadFileAtPathToS3Async = uploadFileAtPathToS3Async;
async function uploadWithPresignedPostWithRetryAsync(file, presignedPost) {
    return await (0, promise_retry_1.default)(async (retry) => {
        // retry fetch errors (usually connection or DNS errors)
        let response;
        try {
            response = await uploadWithPresignedPostAsync(file, presignedPost);
        }
        catch (e) {
            return retry(e);
        }
        // retry 408, 429, 5xx as suggested by google
        if (response.status === 408 ||
            response.status === 429 ||
            (response.status >= 500 && response.status <= 599)) {
            return retry(new Error(`Presigned upload responded with a ${response.status} status`));
        }
        // don't retry other errors
        if (!response.ok) {
            throw new Error(`Presigned upload responded with a ${response.status} status`);
        }
        return response;
    }, 
    // retry parameters match google suggested defaults: https://cloud.google.com/storage/docs/retry-strategy#node.js
    {
        retries: 3,
        factor: 2,
    });
}
exports.uploadWithPresignedPostWithRetryAsync = uploadWithPresignedPostWithRetryAsync;
async function createPresignedPostFormDataAsync(file, presignedPost) {
    const fileStat = await fs_extra_1.default.stat(file);
    const fileSize = fileStat.size;
    const form = new form_data_1.default();
    for (const [fieldKey, fieldValue] of Object.entries(presignedPost.fields)) {
        form.append(fieldKey, fieldValue);
    }
    form.append('file', fs_extra_1.default.createReadStream(file), { knownLength: fileSize });
    return { form, fileSize };
}
async function uploadWithPresignedPostAsync(file, presignedPost) {
    const { form } = await createPresignedPostFormDataAsync(file, presignedPost);
    const formHeaders = form.getHeaders();
    return await (0, fetch_1.default)(presignedPost.url, {
        method: 'POST',
        body: form,
        headers: {
            ...formHeaders,
        },
    });
}
async function uploadWithPresignedPostWithProgressAsync(file, presignedPost, handleProgressEvent) {
    const { form, fileSize } = await createPresignedPostFormDataAsync(file, presignedPost);
    const formHeaders = form.getHeaders();
    const uploadPromise = (0, fetch_1.default)(presignedPost.url, {
        method: 'POST',
        body: form,
        headers: {
            ...formHeaders,
        },
    });
    let currentSize = 0;
    form.addListener('data', (chunk) => {
        currentSize += Buffer.byteLength(chunk);
        handleProgressEvent({
            progress: {
                total: fileSize,
                percent: currentSize / fileSize,
                transferred: currentSize,
            },
        });
    });
    try {
        const response = await uploadPromise;
        handleProgressEvent({ isComplete: true });
        return response;
    }
    catch (error) {
        handleProgressEvent({ isComplete: true, error });
        throw error;
    }
}
/**
 * S3 returns broken URLs, sth like:
 * https://submission-service-archives.s3.amazonaws.com/production%2Fdc98ca84-1473-4cb3-ae81-8c7b291cb27e%2F4424aa95-b985-4e2f-8755-9507b1037c1c
 * This function replaces %2F with /.
 */
function fixS3Url(archiveUrl) {
    const parsed = new url_1.URL(archiveUrl);
    parsed.pathname = decodeURIComponent(parsed.pathname);
    return parsed.toString();
}
exports.fixS3Url = fixS3Url;
